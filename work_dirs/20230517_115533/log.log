[2023-05-17 11:55:33,357 main.py:473 INFO log] Generating class images for prior preservation.
[2023-05-17 11:57:06,971 main.py:628 INFO log] Namespace(adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
adam_weight_decay=0.01,
allow_tf32=True,
center_crop=True,
checkpointing_steps=1,
checkpoints_total_limit=None,
class_data_dir='class_images',
class_prompt='A selfie of a jianqging man',
dataloader_num_workers=0,
enable_xformers_memory_efficient_attention=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
hub_model_id=None,
hub_token=None,
instance_data_dir='imgs/',
instance_prompt='A selfie of a jianqging man',
learning_rate=0.0001,
local_rank=-1,
logging_dir='logs',
lr_num_cycles=1,
lr_power=1.0,
lr_scheduler='constant',
lr_warmup_steps=500,
max_grad_norm=1.0,
max_train_steps=500,
mixed_precision='fp16',
num_class_images=20,
num_train_epochs=25,
num_validation_images=4,
output_dir='work_dirs/20230517_115533',
pre_compute_text_embeddings=False,
pretrained_model_name_or_path='runwayml/stable-diffusion-v1-5',
prior_generation_precision='fp16',
prior_loss_weight=1.0,
push_to_hub=False,
report_to='tensorboard',
resolution=512,
resume_from_checkpoint=None,
revision=None,
sample_batch_size=1,
scale_lr=False,
seed=None,
text_encoder_use_attention_mask=False,
tokenizer_max_length=None,
tokenizer_name=None,
train_batch_size=1,
train_text_encoder=True,
use_8bit_adam=False,
validation_epochs=10,
validation_prompt='A selfie of an asia man',
with_prior_preservation=True)
[2023-05-17 11:57:06,972 main.py:629 INFO log] ***** Running training *****
[2023-05-17 11:57:06,972 main.py:630 INFO log]   Num examples = 20
[2023-05-17 11:57:06,972 main.py:631 INFO log]   Num batches each epoch = 20
[2023-05-17 11:57:06,972 main.py:632 INFO log]   Num Epochs = 25
[2023-05-17 11:57:06,972 main.py:633 INFO log]   Instantaneous batch size per device = 1
[2023-05-17 11:57:06,973 main.py:635 INFO log]   Total train batch size (w. parallel, distributed & accumulation) = 1
[2023-05-17 11:57:06,973 main.py:638 INFO log]   Gradient Accumulation steps = 1
[2023-05-17 11:57:06,973 main.py:640 INFO log]   Total optimization steps = 500
[2023-05-17 11:57:17,896 logging.py:47 INFO log] Saving current state to work_dirs/20230517_115533/checkpoint-1
